{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c61906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b210482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Time Series Forecasting\\\\Time-Series-Forecasting-with-XGBoost\\\\notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28f86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up project paths\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "data_path = PROJECT_ROOT / 'data' / 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb28d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any, Optional, Union, Generator, List\n",
    "from pathlib import Path\n",
    "from myapp.config.config_manager import ConfigManager\n",
    "from myapp.utils.logger import CustomLogger\n",
    "# from myapp.components.data_validation import DataValidator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CleaningRules:\n",
    "    \"\"\"\n",
    "    Define cleaning rules and configurations for energy usage data.\n",
    "    Similar to data_schema but focused on cleaning/repairing data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Columns expected to be cleaned and their data types\n",
    "    expected_columns: Dict[str, str] = {\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "        \"aep_mw\": \"float64\",\n",
    "    }\n",
    "\n",
    "    # Columns allowed to have nulls or not\n",
    "    nullable_columns = set()  # e.g. {\"aep_mw\"} if missing allowed\n",
    "\n",
    "    # Default fill values for missing data (if any)\n",
    "    default_fill_values: Dict[str, Any] = {\n",
    "        # e.g., \"aep_mw\": 0.0  # fill missing with 0 if appropriate\n",
    "    }\n",
    "\n",
    "    # Rules for invalid or erroneous values (min, max, etc.)\n",
    "    value_constraints: Dict[str, Dict[str, Optional[float]]] = {\n",
    "        \"aep_mw\": {\"min\": 0.0, \"max\": None},  # energy should be non-negative\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert columns to expected data types.\n",
    "        \"\"\"\n",
    "        for col, dtype in CleaningRules.expected_columns.items():\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    df[col] = df[col].astype(dtype)\n",
    "                except Exception as e:\n",
    "                    raise ValueError(f\"Error converting column '{col}' to {dtype}: {e}\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def fill_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fill missing values based on default_fill_values or drop if not nullable.\n",
    "        \"\"\"\n",
    "        for col in CleaningRules.expected_columns.keys():\n",
    "            if col in df.columns:\n",
    "                if col in CleaningRules.nullable_columns:\n",
    "                    # If nullable, leave as is or fill with default if specified\n",
    "                    if col in CleaningRules.default_fill_values:\n",
    "                        df[col].fillna(CleaningRules.default_fill_values[col], inplace=True)\n",
    "                else:\n",
    "                    # Not nullable, fill or drop rows\n",
    "                    if col in CleaningRules.default_fill_values:\n",
    "                        df[col].fillna(CleaningRules.default_fill_values[col], inplace=True)\n",
    "                    else:\n",
    "                        # Drop rows with missing in this column\n",
    "                        df.dropna(subset=[col], inplace=True)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_invalid_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Remove or fix rows with invalid values based on constraints.\n",
    "        \"\"\"\n",
    "        for col, constraints in CleaningRules.value_constraints.items():\n",
    "            if col in df.columns:\n",
    "                min_val = constraints.get(\"min\", None)\n",
    "                max_val = constraints.get(\"max\", None)\n",
    "                if min_val is not None:\n",
    "                    df = df[df[col] >= min_val]\n",
    "                if max_val is not None:\n",
    "                    df = df[df[col] <= max_val]\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Remove duplicate rows based on 'datetime' column.\n",
    "        \"\"\"\n",
    "        if 'datetime' in df.columns:\n",
    "            df = df.drop_duplicates(subset=['datetime'])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217778a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Sample mock data with some missing and invalid values\n",
    "data = {\n",
    "    \"datetime\": [\n",
    "        \"2023-01-01 00:00:00\", \n",
    "        \"2023-01-01 01:00:00\", \n",
    "        \"2023-01-01 02:00:00\", \n",
    "        None\n",
    "    ],\n",
    "    \"aep_mw\": [100.0, None, -5.0, 50.0]\n",
    "}\n",
    "\n",
    "df_mock = pd.DataFrame(data)\n",
    "df_mock[\"datetime\"] = pd.to_datetime(df_mock[\"datetime\"])\n",
    "\n",
    "df_mock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from myapp.preprocessing.cleaning_rules import CleaningRules\n",
    "from myapp.preprocessing.data_preprocessing import DataPreprocessing\n",
    "\n",
    "# Create mock data\n",
    "df_mock = pd.DataFrame({\n",
    "    \"datetime\": pd.to_datetime([\"2023-01-01 00:00:00\", \"2023-01-01 01:00:00\", None]),\n",
    "    \"aep_mw\": [100.0, None, -10.0]\n",
    "})\n",
    "\n",
    "# Instantiate and run cleaning\n",
    "preprocessor = DataPreprocessing(logger=None)\n",
    "cleaned_df = preprocessor.clean_data(df_mock)\n",
    "\n",
    "print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b68942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleaningRules:\n",
    "    expected_columns: Dict[str, str] = {\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "        \"aep_mw\": \"float64\",\n",
    "    }\n",
    "\n",
    "    nullable_columns = set()\n",
    "\n",
    "    default_fill_values: Dict[str, Any] = {\n",
    "        \"aep_mw\": 0.0  # example: fill missing energy with 0, adjust as needed\n",
    "    }\n",
    "\n",
    "    value_constraints: Dict[str, Dict[str, Optional[float]]] = {\n",
    "        \"aep_mw\": {\"min\": 0.0, \"max\": None},\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_required_columns(df: pd.DataFrame) -> None:\n",
    "        missing = [col for col in CleaningRules.expected_columns if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        for col, dtype in CleaningRules.expected_columns.items():\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    df[col] = df[col].astype(dtype)\n",
    "                except Exception as e:\n",
    "                    raise ValueError(f\"Error converting column '{col}' to {dtype}: {e}\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def has_missing(df: pd.DataFrame) -> bool:\n",
    "        \"\"\"Check if dataframe has any missing values in expected columns.\"\"\"\n",
    "        return df[CleaningRules.expected_columns.keys()].isnull().any().any()\n",
    "\n",
    "    @staticmethod\n",
    "    def fill_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_copy = df.copy()\n",
    "        for col in CleaningRules.expected_columns.keys():\n",
    "            if col in df_copy.columns and col in CleaningRules.default_fill_values:\n",
    "                df_copy[col] = df_copy[col].fillna(CleaningRules.default_fill_values[col])\n",
    "        return df_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_invalid_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_copy = df.copy()\n",
    "        for col, constraints in CleaningRules.value_constraints.items():\n",
    "            if col in df_copy.columns:\n",
    "                min_val = constraints.get(\"min\")\n",
    "                max_val = constraints.get(\"max\")\n",
    "                if min_val is not None:\n",
    "                    df_copy = df_copy[df_copy[col] >= min_val]\n",
    "                if max_val is not None:\n",
    "                    df_copy = df_copy[df_copy[col] <= max_val]\n",
    "        return df_copy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
